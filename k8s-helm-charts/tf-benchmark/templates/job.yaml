apiVersion: batch/v1
kind: Job
metadata:
  name: {{ template "fullname" . -}}-{{ .Values.parallelism }}-{{ .Values.resources.requests.cpu | lower }}-{{ .Values.resources.requests.memory | lower }}
spec:
  parallelism: {{ .Values.parallelism }}
  template:
    metadata:
      labels:
        app: {{ template "fullname" . }}
    spec:
      containers:
      - name: tfbench
        
        image: tensorflow/tensorflow:nightly-gpu
        command: {{ .Values.command }}
        env:
        - name: MODE
          value: {{ .Values.mode }} 
        - name: LD_LIBRARY_PATH
          value: "$LD_LIBRARY_PATH:/usr/lib/nvidia:/usr/lib/cuda"
        volumeMounts:
        - name: tf-data
          mountPath: /data
        - mountPath: /usr/local/nvidia/bin
          name: bin
        - mountPath: /usr/lib/nvidia
          name: lib
        - mountPath: /usr/lib/cuda
          name: libcuda
        resources:
        {{ if .Values.resources.manage }}
          requests: 
{{ toYaml .Values.resources.requests | indent 12 }}
            alpha.kubernetes.io/nvidia-gpu: 1
          limits:
{{ toYaml .Values.resources.limits | indent 12 }}
            alpha.kubernetes.io/nvidia-gpu: 1
        {{ else }}
          requests: 
            alpha.kubernetes.io/nvidia-gpu: 1
          limits:
            alpha.kubernetes.io/nvidia-gpu: 1
        {{ end }}
      nodeSelector:
{{ toYaml .Values.nodeSelector | indent 8 }}
      restartPolicy: Never
      volumes:
      - name: tf-data
        hostPath: 
          path: {{ .Values.hostPath }}
      - name: bin
        hostPath:
          path: /usr/lib/nvidia-384/bin
      - name: lib
        hostPath:
          path: /usr/lib/nvidia-384
      - name: libcuda
        hostPath:
          path: /usr/lib/x86_64-linux-gnu
